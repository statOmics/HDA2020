<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Adapted by Milan Malfait" />

<meta name="date" content="2020-11-19" />

<title>Analysis of High Dimensional Data - Lab 4</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<script src="site_libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
#rmd-source-code {
  display: none;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HDA2020</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-chalkboard-teacher"></span>
     
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="intro.html">1. Introduction</a>
    </li>
    <li>
      <a href="svd.html">2. Singular Value Decomposition</a>
    </li>
    <li>
      <a href="prediction.html">3. Prediction with High Dimensional Predictors</a>
    </li>
    <li>
      <a href="sparseSvd.html">4. Sparse Singular Value Decomposition</a>
    </li>
    <li>
      <a href="lda.html">5. Linear Discriminant Analysis</a>
    </li>
    <li>
      <a href="lsi.html">6. Large Scale Inference</a>
    </li>
    <li>
      <a href="hclust.html">Paper 1: Intro Hierarchical Clustering</a>
    </li>
    <li>
      <a href="em.html">Paper 1: EM algorithm</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-laptop"></span>
     
    Practicals
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Lab1-Intro-SVD.html">Lab 1</a>
    </li>
    <li>
      <a href="Lab2-PCA.html">Lab 2</a>
    </li>
    <li>
      <a href="Lab3-Penalized-Regression.html">Lab 3</a>
    </li>
    <li>
      <a href="Lab4-Sparse-PCA-LDA.html">Lab 4</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/statOmics/HDA2020">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="http://statomics.github.io/">statOmics</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Analysis of High Dimensional Data - Lab 4</h1>
<h3 class="subtitle">Sparse PCA and LDA</h3>
<h4 class="author">Adapted by Milan Malfait</h4>
<h4 class="date">19 Nov 2020</h4>

</div>


<hr />
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">## install packages with:</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co">## install.packages(c(&quot;glmnet&quot;, &quot;MASS&quot;))</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="kw">library</span>(glmnet)</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="kw">library</span>(MASS)</span></code></pre></div>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p><strong>In this lab session we will look at the following topics</strong></p>
<ul>
<li>Methods to set some of the loadings exactly to zero in a PCA.</li>
<li>Use <code>glmnet()</code> to add penalties on principal component loadings.</li>
<li>Use LDA to understand differences between groups in a high dimensional space.</li>
</ul>
<div id="the-dataset" class="section level2 unnumbered">
<h2>The dataset</h2>
<p>In this practical session, we use the dataset by <span class="citation">Alon et al. (1999)</span> on gene expression levels in 40 tumour and 22 normal colon tissue samples. They checked a total of 6500 human genes using the Affymetrix oligonucleotide array. You can read the data in as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a>Alon1999 &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;https://github.com/statOmics/HDA2020/raw/data/Alon1999.csv&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="kw">str</span>(Alon1999[, <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>])</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co">#&gt; &#39;data.frame&#39;:    62 obs. of  10 variables:</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co">#&gt;  $ Y : chr  &quot;t&quot; &quot;n&quot; &quot;t&quot; &quot;n&quot; ...</span></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="co">#&gt;  $ X1: num  8589 9164 3826 6246 3230 ...</span></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="co">#&gt;  $ X2: num  5468 6720 6970 7824 3694 ...</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co">#&gt;  $ X3: num  4263 4883 5370 5956 3401 ...</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="co">#&gt;  $ X4: num  4065 3718 4706 3976 3464 ...</span></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="co">#&gt;  $ X5: num  1998 2015 1167 2003 2181 ...</span></span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="co">#&gt;  $ X6: num  5282 5570 1572 2131 2923 ...</span></span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="co">#&gt;  $ X7: num  2170 3849 1325 1531 2069 ...</span></span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="co">#&gt;  $ X8: num  2773 2793 1472 1715 2949 ...</span></span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="co">#&gt;  $ X9: num  7526 7018 3297 3870 3303 ...</span></span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="kw">table</span>(Alon1999<span class="op">$</span>Y)</span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="co">#&gt; </span></span>
<span id="cb2-16"><a href="#cb2-16"></a><span class="co">#&gt;  n  t </span></span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="co">#&gt; 22 40</span></span></code></pre></div>
<p>The dataset contains one variable named <code>Y</code> with the values <code>t</code> and <code>n</code>. This variable indicates whether the sample came from tumourous (<code>t</code>) or normal (<code>n</code>) tissue.</p>
<p>The goal of this practical is to find the best subset/combination of genes to detect tumourous tissue. As in <span class="citation">Alon et al. (1999)</span>, we use the 2000 genes with the highest minimal intensity across the samples.</p>
</div>
</div>
<div id="sparse-pca" class="section level1">
<h1><span class="header-section-number">2</span> Sparse PCA</h1>
<p>In order to work easily with the data, first construct a scaled matrix <code>X</code> and a vector <code>Y</code> which gives the scaled predictors and the response variable:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>X &lt;-<span class="st"> </span><span class="kw">scale</span>(Alon1999[, <span class="dv">-1</span>])</span>
<span id="cb3-2"><a href="#cb3-2"></a>Y &lt;-<span class="st"> </span><span class="kw">as.factor</span>(Alon1999[, <span class="dv">1</span>])</span></code></pre></div>
<p>Use these objects to solve the following exercises.</p>
<div id="exercises" class="section level2 unnumbered">
<h2>Exercises</h2>
<div id="perform-a-svd-on-x-and-store-the-scores-of-the-pcs-in-a-matrix-z." class="section level4 unnumbered">
<h4>1. Perform a SVD on <code>X</code>, and store the scores of the PCs in a matrix <code>Z</code>.</h4>
<details>
<p><summary>Solution</summary></p>
<p>Using <code>svd</code>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a>svd_X &lt;-<span class="st"> </span><span class="kw">svd</span>(X)</span>
<span id="cb4-2"><a href="#cb4-2"></a>Z &lt;-<span class="st"> </span>svd_X<span class="op">$</span>u <span class="op">%*%</span><span class="st"> </span><span class="kw">diag</span>(svd_X<span class="op">$</span>d) <span class="co"># Calculate the scores</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>V &lt;-<span class="st"> </span>svd_X<span class="op">$</span>v                 <span class="co"># Calculate the loadings</span></span></code></pre></div>
<p>Using <code>prcomp</code>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co">## X is already centered and scaled so no need to do again</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>pca_x &lt;-<span class="st"> </span><span class="kw">prcomp</span>(X, <span class="dt">center =</span> <span class="ot">FALSE</span>, <span class="dt">scale. =</span> <span class="ot">FALSE</span>)</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="co">## The scores are given by `pca_x$x`, the loadings are `pca_x$rotation`</span></span></code></pre></div>
</details>
</div>
<div id="plot-the-singular-values-and-confirm-that-the-first-and-second-pcs-can-approximate-the-data-to-some-extent." class="section level4 unnumbered">
<h4>2. Plot the singular values and confirm that the first and second PCs can approximate the data to some extent.</h4>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="co">## Plotting parameters</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="kw">par</span>(<span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb6-3"><a href="#cb6-3"></a></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="kw">plot</span>(svd_X<span class="op">$</span>d, <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Singular values&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;PCs&quot;</span>)</span>
<span id="cb6-5"><a href="#cb6-5"></a></span>
<span id="cb6-6"><a href="#cb6-6"></a><span class="co">## Percentage variance explained for each PC</span></span>
<span id="cb6-7"><a href="#cb6-7"></a>var_explained &lt;-<span class="st"> </span>svd_X<span class="op">$</span>d<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(svd_X<span class="op">$</span>d<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="kw">plot</span>(var_explained,</span>
<span id="cb6-9"><a href="#cb6-9"></a>  <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Percent variance explained&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;PCs&quot;</span>,</span>
<span id="cb6-10"><a href="#cb6-10"></a>  <span class="dt">col =</span> <span class="dv">2</span></span>
<span id="cb6-11"><a href="#cb6-11"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/pca-singular_values-plot-1.png" width="100%" style="display: block; margin: auto;" /></p>
</details>
</div>
<div id="plot-the-first-two-pcs-and-use-different-colours-for-tumornormal-tissue." class="section level4 unnumbered">
<h4>3. Plot the first two PCs and use different colours for tumor/normal tissue.</h4>
<p>In order to plot different colors and add a legend with base <code>R</code> plotting, you can do the following:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb7-2"><a href="#cb7-2"></a>cols &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;n&quot;</span> =<span class="st"> &quot;red&quot;</span>, <span class="st">&quot;t&quot;</span> =<span class="st"> &quot;blue&quot;</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="kw">plot</span>(X[, <span class="dv">1</span>], X[, <span class="dv">2</span>], <span class="dt">col =</span> cols[Y], <span class="dt">pch =</span> <span class="dv">19</span>)</span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;Normal&quot;</span>, <span class="st">&quot;Tumor&quot;</span>),</span>
<span id="cb7-5"><a href="#cb7-5"></a>  <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>),</span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">title =</span> <span class="st">&quot;Tissue&quot;</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>This plots the first two dimensions of the <code>X</code> (!) matrix with solid points (<code>pch = 19</code>), and the color red for normal tissue and blue for tumorous tissue. You can adapt this code to create the proper plot.</p>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>cols &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;n&quot;</span> =<span class="st"> &quot;red&quot;</span>, <span class="st">&quot;t&quot;</span> =<span class="st"> &quot;blue&quot;</span>)</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="kw">plot</span>(Z[, <span class="dv">1</span>], Z[, <span class="dv">2</span>],</span>
<span id="cb8-3"><a href="#cb8-3"></a>  <span class="dt">col =</span> cols[Y],</span>
<span id="cb8-4"><a href="#cb8-4"></a>  <span class="dt">xlab =</span> <span class="st">&quot;PC1&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;PC2&quot;</span>, <span class="dt">pch =</span> <span class="dv">19</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>)</span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;Normal&quot;</span>, <span class="st">&quot;Tumor&quot;</span>),</span>
<span id="cb8-7"><a href="#cb8-7"></a>  <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>),</span>
<span id="cb8-8"><a href="#cb8-8"></a>  <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">title =</span> <span class="st">&quot;Tissue&quot;</span></span>
<span id="cb8-9"><a href="#cb8-9"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/pca-plot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p><strong>Interpretation:</strong> using only the first 2 PCs does not seem to separate the tumour and normal cases clearly.</p>
</details>
</div>
<div id="plot-histograms-of-the-loadings-of-the-first-and-second-pcs.-which-loadings-are-the-most-important" class="section level4 unnumbered">
<h4>4. Plot histograms of the loadings of the first and second PCs. Which loadings are the most important?</h4>
<p>You can use the <code>hist</code> function to plot a histogram. Be sure to you use an appropriate value for the <code>breaks</code> argument.</p>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="co"># First</span></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="kw">hist</span>(V[, <span class="dv">1</span>], <span class="dt">breaks =</span> <span class="dv">50</span>, <span class="dt">xlab =</span> <span class="st">&quot;PC 1 loadings&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="co"># Add vertical line at 95% quantile</span></span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">quantile</span>(V[, <span class="dv">1</span>], <span class="fl">0.95</span>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb9-6"><a href="#cb9-6"></a></span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="co"># Second</span></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="kw">hist</span>(V[, <span class="dv">2</span>], <span class="dt">breaks =</span> <span class="dv">50</span>, <span class="dt">xlab =</span> <span class="st">&quot;PC 2 loadings&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb9-9"><a href="#cb9-9"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">c</span>(</span>
<span id="cb9-10"><a href="#cb9-10"></a>  <span class="kw">quantile</span>(V[, <span class="dv">2</span>], <span class="fl">0.05</span>),</span>
<span id="cb9-11"><a href="#cb9-11"></a>  <span class="kw">quantile</span>(V[, <span class="dv">2</span>], <span class="fl">0.95</span>)</span>
<span id="cb9-12"><a href="#cb9-12"></a>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/pc-loadings-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Vertical lines were added at the 95th percentile for PC1 and the 5th and 95th percentiles for PC2 to reflect where the “highest” (in absolute value) loadings are situated (no negative loadings for PC1, so only showing the 95th percentile).</p>
<p><strong>Interpretation:</strong> remember that the PC loadings reflect the <em>contributions</em> of each feature (in this case: gene) to the PC. From these histograms it should be clear that only a minor fraction of the genes are really driving these first 2 PCs, especially for PC 2 (where the bulk of genes has loadings close to 0).</p>
</details>
</div>
<div id="we-know-that-the-first-pc-mathbfz_1-is-given-by" class="section level4 unnumbered">
<h4>5. We know that the first PC <span class="math inline">\(\mathbf{Z_1}\)</span>, is given by</h4>
<p><span class="math display">\[
  \mathbf{Z_1}=\mathbf{X} \mathbf{V_1}
  \]</span></p>
<p>Where <span class="math inline">\(\mathbf{V_1}\)</span> are the loadings of the first PC. If we put this in regression notation, we get</p>
<p><span class="math display">\[
  \mathbf{Y}=\mathbf{X}\boldsymbol{\beta}
  \]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\beta}\)</span> now represent the <span class="math inline">\(\mathbf{V_1}\)</span> loadings, and <span class="math inline">\(\mathbf{Y}\)</span> is <span class="math inline">\(\mathbf{Z_1}\)</span>.</p>
<p>Recall that the ridge regression solution for <span class="math inline">\(\boldsymbol{\beta}\)</span> is given by</p>
<p><span class="math display">\[
  \boldsymbol{\beta}_{\text{ridge}}
    = (\mathbf{X^TX}+\gamma\mathbf{I})^{-1}\mathbf{X}^T\mathbf Y
  \]</span></p>
<p><strong>Question:</strong> Replace <span class="math inline">\(\mathbf{Y}\)</span> with <span class="math inline">\(\mathbf{Z_1}\)</span> and verify in <code>R</code> that</p>
<p><span class="math display">\[
  \mathbf V_1 = 
    \frac{\boldsymbol\beta_{\text{ridge}}}{\|\boldsymbol\beta_{\text{ridge}}\|_2}
  \]</span></p>
<p>for any <span class="math inline">\(\gamma &gt; 0\)</span> of your choice. Remember that <span class="math inline">\(\|\boldsymbol\beta_{\text{ridge}}\|_2 = \sqrt{\sum_{j=1}^p \beta_j^2}\)</span></p>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>p &lt;-<span class="st"> </span><span class="kw">dim</span>(X)[<span class="dv">2</span>]</span>
<span id="cb10-2"><a href="#cb10-2"></a></span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="co"># Let&#39;s take a ridiculously large gamma: 200</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>tXX_gamma_I &lt;-<span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X <span class="op">+</span><span class="st"> </span><span class="dv">200</span> <span class="op">*</span><span class="st"> </span><span class="kw">diag</span>(p)</span>
<span id="cb10-5"><a href="#cb10-5"></a></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="co">## This might take a while to calculate</span></span>
<span id="cb10-7"><a href="#cb10-7"></a>beta_ridge &lt;-<span class="st"> </span><span class="kw">solve</span>(tXX_gamma_I) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>Z[, <span class="dv">1</span>]</span>
<span id="cb10-8"><a href="#cb10-8"></a></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="co">#||beta_ridge||_2</span></span>
<span id="cb10-10"><a href="#cb10-10"></a>mag_beta_ridge &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">sum</span>(beta_ridge<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<p>For comparison, let’s plot <span class="math inline">\(\boldsymbol\beta_{\text{ridge}} / \|\boldsymbol\beta_{\text{ridge}}\|_2\)</span> against the PC1 loadings <span class="math inline">\(\mathbf V_1\)</span>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb11-2"><a href="#cb11-2"></a></span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="co"># Plot against the loadings</span></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="kw">plot</span>(svd_X<span class="op">$</span>v[, <span class="dv">1</span>], beta_ridge <span class="op">/</span><span class="st"> </span>mag_beta_ridge,</span>
<span id="cb11-5"><a href="#cb11-5"></a>  <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="st">&quot;V&quot;</span>[<span class="dv">1</span>]),</span>
<span id="cb11-6"><a href="#cb11-6"></a>  <span class="dt">ylab =</span> <span class="kw">expression</span>(beta[<span class="st">&quot;ridge&quot;</span>] <span class="op">/</span><span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;||&quot;</span>, beta, <span class="st">&quot;||&quot;</span>)[<span class="dv">2</span>]),</span>
<span id="cb11-7"><a href="#cb11-7"></a>  <span class="dt">pch =</span> <span class="dv">19</span></span>
<span id="cb11-8"><a href="#cb11-8"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/beta_ridge-vs-V1-plot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a><span class="co"># Or just simply take the difference between them</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="kw">max</span>(<span class="kw">abs</span>(svd_X<span class="op">$</span>v[, <span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>beta_ridge <span class="op">/</span><span class="st"> </span>mag_beta_ridge))</span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="co">#&gt; [1] 5.187517e-14</span></span></code></pre></div>
</details>
<p>Then you’ve proven that the loadings of the PCs can be computed from the ridge regression coefficients.</p>
<p>We can now move on to sparse PCA, where we use penalised regression to set some of the loadings (<span class="math inline">\(\boldsymbol{\beta}\)</span>s) to zero.</p>
</div>
<div id="we-have-seen-elastic-net-type-penalties.-if-we-call-the-loadings-of-the-first-pc-as-boldsymbolbeta-and-denote-pc1-as-mathbfy-we-saw-that-boldsymbolbeta-can-be-derived-by-minimising-the-sse" class="section level4 unnumbered">
<h4>6. We have seen elastic net type penalties. If we call the loadings of the first PC as <span class="math inline">\(\boldsymbol{\beta}\)</span> and denote PC1 as <span class="math inline">\(\mathbf{Y}\)</span>, we saw that <span class="math inline">\(\boldsymbol{\beta}\)</span> can be derived by minimising the SSE:</h4>
<p><span class="math display">\[
  \text{SSE}=\|\mathbf Y-\mathbf{X}\boldsymbol \beta\|^2_2+\gamma\|\boldsymbol \beta\|^2_2 \text{ for any } \gamma&gt;0).
  \]</span></p>
<p>Note that this equality holds for any positive <span class="math inline">\(\gamma\)</span>. So we can’t penalise the <span class="math inline">\(\boldsymbol\beta\)</span>s not being zero by choosing a different <span class="math inline">\(\gamma\)</span>. Remember that for ridge regression, the <span class="math inline">\(\beta\)</span>’s only become 0 for <span class="math inline">\(\gamma = \infty\)</span>. Fortunately we have other tools.</p>
<p>In addition to the <span class="math inline">\(L_2\)</span> penalization, we can use the <span class="math inline">\(L_1\)</span> penalization of Lasso. This allows us to force some of the <span class="math inline">\(\boldsymbol\beta\)</span>s to become zero. The new SSE will be of the form:</p>
<p><span class="math display">\[
  \text{SSE}=\|\mathbf Y-\mathbf{X}\boldsymbol \beta\|^2_2+\gamma\|\boldsymbol \beta\|^2_2 +\gamma_1\|\boldsymbol \beta\|_1.
  \]</span></p>
<p>This is exactly the elastic net SSE, and <span class="math inline">\(\gamma_1\)</span> is the Lasso type penalty that sets loadings to zero.</p>
<p>Now use the <code>glmnet</code> and <code>cv.glmnet</code> functions to select an appropriate number of non-zero loadings for the first and second PCs. Use <code>alpha = 0.5</code> in your elastic net models and use <code>Z1</code> and <code>Z2</code> as the response variables (you should fit 2 separate models).</p>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="co"># For PC1</span></span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="kw">set.seed</span>(<span class="dv">45</span>)</span>
<span id="cb13-4"><a href="#cb13-4"></a>fit_loadings1 &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(X, Z[, <span class="dv">1</span>],</span>
<span id="cb13-5"><a href="#cb13-5"></a>  <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">nfolds =</span> <span class="dv">5</span></span>
<span id="cb13-6"><a href="#cb13-6"></a>)</span>
<span id="cb13-7"><a href="#cb13-7"></a><span class="kw">plot</span>(fit_loadings1, <span class="dt">main =</span> <span class="st">&quot;PC1&quot;</span>)</span>
<span id="cb13-8"><a href="#cb13-8"></a></span>
<span id="cb13-9"><a href="#cb13-9"></a><span class="co"># For PC2</span></span>
<span id="cb13-10"><a href="#cb13-10"></a><span class="kw">set.seed</span>(<span class="dv">45</span>)</span>
<span id="cb13-11"><a href="#cb13-11"></a>fit_loadings2 &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(X, Z[, <span class="dv">2</span>], <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">nfolds =</span> <span class="dv">5</span>)</span>
<span id="cb13-12"><a href="#cb13-12"></a><span class="kw">plot</span>(fit_loadings2, <span class="dt">main =</span> <span class="st">&quot;PC2&quot;</span>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/PC-cv_glmnet-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>To see how many features are important for each fit, we can make coefficient profile plots. Note that the actual <code>glmnet</code> fit objects are included in the <code>cv.glmnet</code> objects under <code>$glmnet.fit</code>.</p>
<p>I added vertical dashed lines at <code>lambda.min</code> and <code>lambda.1se</code>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="kw">plot</span>(fit_loadings1<span class="op">$</span>glmnet.fit, <span class="dt">main =</span> <span class="st">&quot;PC1&quot;</span>, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>)</span>
<span id="cb14-3"><a href="#cb14-3"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(fit_loadings1<span class="op">$</span>lambda.min), <span class="dt">lty =</span> <span class="dv">3</span>)</span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(fit_loadings1<span class="op">$</span>lambda<span class="fl">.1</span>se), <span class="dt">lty =</span> <span class="dv">3</span>)</span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="kw">plot</span>(fit_loadings2<span class="op">$</span>glmnet.fit, <span class="dt">main =</span> <span class="st">&quot;PC2&quot;</span>, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>)</span>
<span id="cb14-6"><a href="#cb14-6"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(fit_loadings2<span class="op">$</span>lambda.min), <span class="dt">lty =</span> <span class="dv">3</span>)</span>
<span id="cb14-7"><a href="#cb14-7"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">log</span>(fit_loadings2<span class="op">$</span>lambda<span class="fl">.1</span>se), <span class="dt">lty =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/PC-glmnet-coefficient-plots-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>To get the exact number of non-zero coefficients for <code>lambda.min</code> and <code>lambda.1se</code>, just print the <code>cv.glmnet</code> objects.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a>fit_loadings1</span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="co">#&gt; </span></span>
<span id="cb15-3"><a href="#cb15-3"></a><span class="co">#&gt; Call:  cv.glmnet(x = X, y = Z[, 1], nfolds = 5, alpha = 0.5) </span></span>
<span id="cb15-4"><a href="#cb15-4"></a><span class="co">#&gt; </span></span>
<span id="cb15-5"><a href="#cb15-5"></a><span class="co">#&gt; Measure: Mean-Squared Error </span></span>
<span id="cb15-6"><a href="#cb15-6"></a><span class="co">#&gt; </span></span>
<span id="cb15-7"><a href="#cb15-7"></a><span class="co">#&gt;     Lambda Measure    SE Nonzero</span></span>
<span id="cb15-8"><a href="#cb15-8"></a><span class="co">#&gt; min  1.195   10.88 1.888     101</span></span>
<span id="cb15-9"><a href="#cb15-9"></a><span class="co">#&gt; 1se  1.655   12.68 1.742      96</span></span>
<span id="cb15-10"><a href="#cb15-10"></a>fit_loadings2</span>
<span id="cb15-11"><a href="#cb15-11"></a><span class="co">#&gt; </span></span>
<span id="cb15-12"><a href="#cb15-12"></a><span class="co">#&gt; Call:  cv.glmnet(x = X, y = Z[, 2], nfolds = 5, alpha = 0.5) </span></span>
<span id="cb15-13"><a href="#cb15-13"></a><span class="co">#&gt; </span></span>
<span id="cb15-14"><a href="#cb15-14"></a><span class="co">#&gt; Measure: Mean-Squared Error </span></span>
<span id="cb15-15"><a href="#cb15-15"></a><span class="co">#&gt; </span></span>
<span id="cb15-16"><a href="#cb15-16"></a><span class="co">#&gt;     Lambda Measure    SE Nonzero</span></span>
<span id="cb15-17"><a href="#cb15-17"></a><span class="co">#&gt; min 0.2923   11.70 4.123      80</span></span>
<span id="cb15-18"><a href="#cb15-18"></a><span class="co">#&gt; 1se 1.1800   15.79 6.171      67</span></span></code></pre></div>
<p><strong>Interpretation:</strong> for PC1, we see that around 90 to 100 genes are most important, based on the range of <span class="math inline">\(\gamma\)</span> (<code>lambda</code>) values between <code>lambda.min</code> and <code>lambda.1se</code>. Similarly, for PC2 we get around 65 - 80 genes. With this information, we can now choose one of the <code>lambda</code> values and construct PCs that will have non-zero loadings for only a few genes.</p>
</details>
</div>
<div id="plot-your-newly-derived-first-and-second-pcs-and-use-different-colors-for-the-tumor-and-normal-tissues.-how-well-do-these-new-pcs-separate-the-response-classes-compare-this-to-the-plot-in-exercise-3.-formulate-a-conclusion-based-on-the-two-graphs." class="section level4 unnumbered">
<h4>7. Plot your newly derived first and second PCs and use different colors for the tumor and normal tissues. How well do these new PCs separate the response classes? Compare this to the plot in exercise 3. Formulate a conclusion based on the two graphs.</h4>
<p>Use <code>lambda.1se</code> as your choice for <span class="math inline">\(\gamma\)</span>. You can extract the coefficients (<span class="math inline">\(\beta\)</span>’s) from the <code>cv.glmnet</code> objects using the <code>coef</code> function, set the <code>s</code> argument to the chosen <span class="math inline">\(\gamma\)</span>. This will return a <em>sparse matrix</em> by default, so you might want to use <code>as.vector</code> to convert to a more friendly format.</p>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>sparse_loadings1 &lt;-<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">coef</span>(fit_loadings1, <span class="dt">s =</span> fit_loadings1<span class="op">$</span>lambda<span class="fl">.1</span>se))</span>
<span id="cb16-2"><a href="#cb16-2"></a>sparse_loadings2 &lt;-<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">coef</span>(fit_loadings2, <span class="dt">s =</span> fit_loadings2<span class="op">$</span>lambda<span class="fl">.1</span>se))</span>
<span id="cb16-3"><a href="#cb16-3"></a></span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="co">## How many non-zero loadings do we have (excluding the intercept)?</span></span>
<span id="cb16-5"><a href="#cb16-5"></a>(non_zero1 &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(sparse_loadings1[<span class="op">-</span><span class="dv">1</span>]) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))</span>
<span id="cb16-6"><a href="#cb16-6"></a><span class="co">#&gt; [1] 96</span></span>
<span id="cb16-7"><a href="#cb16-7"></a>(non_zero2 &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(sparse_loadings2[<span class="op">-</span><span class="dv">1</span>]) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))</span>
<span id="cb16-8"><a href="#cb16-8"></a><span class="co">#&gt; [1] 67</span></span>
<span id="cb16-9"><a href="#cb16-9"></a></span>
<span id="cb16-10"><a href="#cb16-10"></a>SPC1 &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>sparse_loadings1[<span class="op">-</span><span class="dv">1</span>] <span class="co"># without the intercept</span></span>
<span id="cb16-11"><a href="#cb16-11"></a>SPC2 &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>sparse_loadings2[<span class="op">-</span><span class="dv">1</span>] <span class="co"># without the intercept</span></span>
<span id="cb16-12"><a href="#cb16-12"></a></span>
<span id="cb16-13"><a href="#cb16-13"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb16-14"><a href="#cb16-14"></a><span class="kw">plot</span>(Z[, <span class="dv">1</span>], Z[, <span class="dv">2</span>],</span>
<span id="cb16-15"><a href="#cb16-15"></a>  <span class="dt">col =</span> cols[Y], <span class="dt">xlab =</span> <span class="st">&quot;PC1&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;PC2&quot;</span>, <span class="dt">pch =</span> <span class="dv">16</span>,</span>
<span id="cb16-16"><a href="#cb16-16"></a>  <span class="dt">main =</span> <span class="st">&quot;All 2000 genes </span><span class="ch">\n</span><span class="st">for PC1 and PC2&quot;</span></span>
<span id="cb16-17"><a href="#cb16-17"></a>)</span>
<span id="cb16-18"><a href="#cb16-18"></a><span class="kw">legend</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">-25</span>,</span>
<span id="cb16-19"><a href="#cb16-19"></a>  <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;Normal tissue&quot;</span>, <span class="st">&quot;Tumor tissue&quot;</span>), <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb16-20"><a href="#cb16-20"></a>  <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="dt">pch =</span> <span class="kw">c</span>(<span class="dv">16</span>, <span class="dv">16</span>), <span class="dt">cex =</span> <span class="dv">1</span></span>
<span id="cb16-21"><a href="#cb16-21"></a>)</span>
<span id="cb16-22"><a href="#cb16-22"></a><span class="kw">plot</span>(SPC1, SPC2,</span>
<span id="cb16-23"><a href="#cb16-23"></a>  <span class="dt">col =</span> cols[Y], <span class="dt">xlab =</span> <span class="st">&quot;SPC1&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;SPC2&quot;</span>, <span class="dt">pch =</span> <span class="dv">16</span>,</span>
<span id="cb16-24"><a href="#cb16-24"></a>  <span class="dt">main =</span> <span class="kw">paste</span>(non_zero1, <span class="st">&quot;genes for SPC1 </span><span class="ch">\n</span><span class="st"> and&quot;</span>, non_zero2, <span class="st">&quot;genes for SPC2&quot;</span>)</span>
<span id="cb16-25"><a href="#cb16-25"></a>)</span>
<span id="cb16-26"><a href="#cb16-26"></a><span class="kw">legend</span>(<span class="op">-</span><span class="dv">45</span>, <span class="dv">-25</span>,</span>
<span id="cb16-27"><a href="#cb16-27"></a>  <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;Normal tissue&quot;</span>, <span class="st">&quot;Tumor tissue&quot;</span>), <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb16-28"><a href="#cb16-28"></a>  <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="dt">pch =</span> <span class="kw">c</span>(<span class="dv">16</span>, <span class="dv">16</span>), <span class="dt">cex =</span> <span class="dv">1</span></span>
<span id="cb16-29"><a href="#cb16-29"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/sparse-PCA-plots-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p><strong>Conclusion:</strong> Only about 4.80% (96) of the genes are useful for PC1 and only about 3.35% (67) of the genes are useful for PC2 . Sparse PCA has succeeded in setting the uninformative genes/loadings to zero. In seperating normal and tumour tissues, SPCA performs vitually the same as PCA. The key point here is that SPCA uses only a minor proportion of the original features to achieve the same results, suggesting that the largest variability of the data is only driven by a minority of features.</p>
</details>
</div>
</div>
</div>
<div id="lda" class="section level1">
<h1><span class="header-section-number">3</span> LDA</h1>
<p>In this section, we will perform LDA on the gene data to get a clear understanding on the genes responsible for separating the tumor and normal tissue groups.</p>
<p>Remember that the LDA problem can be stated as</p>
<p><span class="math display">\[
\mathbf{v}
  = \text{ArgMax}_a \frac{\mathbf{a^T B a}}{\mathbf{a^T W a}}
    \text{ subject to }
    \mathbf{a^T W a} = 1
\]</span></p>
<p>Which is equivalent to the eigenvalue/eigenvector problem</p>
<p><span class="math display">\[
\mathbf W^{-1} \mathbf B \mathbf a=\lambda \mathbf a
\]</span></p>
<p>In our case, where we only have two groups, only one solution exists. This is the eigenvector <span class="math inline">\(\mathbf v\)</span> and its eigenvalue. We can then write the PC-scores as</p>
<p><span class="math display">\[
\mathbf Z=\mathbf X \mathbf v
\]</span></p>
<div id="exercises-1" class="section level2 unnumbered">
<h2>Exercises</h2>
<div id="the-function-lda-in-the-mass-package-performs-lda.-similar-to-the-glmnet-function-you-will-need-to-supply-an-x-argument.-the-argument-grouping-is-the-vector-with-the-response-and-this-has-to-be-a-factor-variable.-you-have-that-stored-as-y.-fit-an-lda-on-x-with-grouping-y." class="section level4 unnumbered">
<h4>1. The function <code>lda()</code> in the <code>MASS</code> package performs LDA. Similar to the <code>glmnet()</code> function, you will need to supply an <code>x</code> argument. The argument <code>grouping</code> is the vector with the response, and this has to be a factor variable. You have that stored as <code>Y</code>. Fit an LDA on <code>X</code> with grouping <code>Y</code>.</h4>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a><span class="co">## Perform LDA</span></span>
<span id="cb17-2"><a href="#cb17-2"></a>alon_lda &lt;-<span class="st"> </span><span class="kw">lda</span>(<span class="dt">x =</span> X, <span class="dt">grouping =</span> Y)</span>
<span id="cb17-3"><a href="#cb17-3"></a><span class="co">#&gt; Warning in lda.default(x, grouping, ...): variables are collinear</span></span></code></pre></div>
<p>Note the warning regarding collinearity.</p>
</details>
</div>
<div id="mathbf-v-can-be-extracted-from-the-object-as-the-element-scaling.-extract-this-and-call-it-v1." class="section level4 unnumbered">
<h4>2. <span class="math inline">\(\mathbf v\)</span> can be extracted from the object as the element <code>scaling</code>. Extract this and call it <code>V1</code>.</h4>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a>V1 &lt;-<span class="st"> </span>alon_lda<span class="op">$</span>scaling</span></code></pre></div>
</details>
</div>
<div id="compute-mathbf-z-and-call-it-z1." class="section level4 unnumbered">
<h4>3. Compute <span class="math inline">\(\mathbf Z\)</span> and call it <code>Z1</code>.</h4>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a>Z1 &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>V1</span></code></pre></div>
</details>
</div>
<div id="now-check-to-see-how-well-your-single-ldaz1-separates-the-tumour-and-normal-tissues-groups.-compare-it-to-the-plot-in-3-of-the-previous-exercise-and-observe-whether-lda-performs-better-in-separating-the-two-groups." class="section level4 unnumbered">
<h4>4. Now check to see how well your single LDA/<code>Z1</code> separates the tumour and normal tissues groups. Compare it to the plot in (3) of the previous exercise, and observe whether LDA performs better in separating the two groups.</h4>
<p>You could use a boxplot for visualization, but feel free to be creative!</p>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb20-2"><a href="#cb20-2"></a><span class="kw">boxplot</span>(Z1 <span class="op">~</span><span class="st"> </span>Y, <span class="dt">col =</span> cols, <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="st">&quot;Z&quot;</span>[<span class="dv">1</span>]), </span>
<span id="cb20-3"><a href="#cb20-3"></a>        <span class="dt">main =</span> <span class="st">&quot;Separation of normal and tumour samples by LDA&quot;</span>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/unnamed-chunk-10-1.png" width="100%" style="display: block; margin: auto;" /></p>
</details>
</div>
<div id="as-was-the-case-with-the-first-and-second-pc-z1-is-a-linear-combination-determined-by-the-loadings-mathbf-v.-these-are-non-zero-for-all-genes.-to-get-a-few-interesting-genes-you-can-use-a-sparse-lda.-note-that-you-can-use-the-package-sparselda-with-the-function-sda-to-perform-this-analysis-but-lets-do-this-as-we-did-for-sparse-pca." class="section level4 unnumbered">
<h4>5. As was the case with the first and second PC, <code>Z1</code> is a linear combination determined by the loadings <span class="math inline">\(\mathbf v\)</span>. These are non-zero for all genes. To get a few interesting genes, you can use a sparse LDA. Note that you can use the package <code>sparseLDA</code> with the function <code>sda()</code> to perform this analysis, but let’s do this as we did for sparse PCA.</h4>
<ol style="list-style-type: lower-alpha">
<li>Use the <code>cv.glmnet</code> function with <code>x=X</code>, <code>y=Z1</code> and <code>alpha=0.5</code> to select an appropriate number of non-zero genes for the LDA.</li>
</ol>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="kw">set.seed</span>(<span class="dv">45</span>)</span>
<span id="cb21-2"><a href="#cb21-2"></a>lda_loadings &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(X, Z1, <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">nfolds =</span> <span class="dv">5</span>)</span>
<span id="cb21-3"><a href="#cb21-3"></a><span class="kw">plot</span>(lda_loadings)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/unnamed-chunk-11-1.png" width="100%" style="display: block; margin: auto;" /></p>
</details>
<ol start="2" style="list-style-type: lower-alpha">
<li>Check to see how well this subset of genes does in separating the tumour and normal tissue groups. Are they as effective as the entire set of genes?</li>
</ol>
<details>
<p><summary>Solution</summary></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a>sparse_lda_loadings &lt;-<span class="st"> </span><span class="kw">as.vector</span>(</span>
<span id="cb22-2"><a href="#cb22-2"></a>  <span class="kw">coef</span>(lda_loadings, <span class="dt">s =</span> lda_loadings<span class="op">$</span>lambda<span class="fl">.1</span>se)</span>
<span id="cb22-3"><a href="#cb22-3"></a>)</span>
<span id="cb22-4"><a href="#cb22-4"></a></span>
<span id="cb22-5"><a href="#cb22-5"></a><span class="co"># See the genes involved</span></span>
<span id="cb22-6"><a href="#cb22-6"></a><span class="kw">plot</span>(sparse_lda_loadings[sparse_lda_loadings <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>],</span>
<span id="cb22-7"><a href="#cb22-7"></a>  <span class="dt">pch =</span> <span class="dv">16</span>, <span class="dt">type =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">20</span>)</span>
<span id="cb22-8"><a href="#cb22-8"></a>)</span>
<span id="cb22-9"><a href="#cb22-9"></a><span class="kw">text</span>(</span>
<span id="cb22-10"><a href="#cb22-10"></a>  sparse_lda_loadings[sparse_lda_loadings <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>],</span>
<span id="cb22-11"><a href="#cb22-11"></a>  <span class="kw">colnames</span>(X)[sparse_lda_loadings <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>]</span>
<span id="cb22-12"><a href="#cb22-12"></a>)</span>
<span id="cb22-13"><a href="#cb22-13"></a><span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">lwd =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/unnamed-chunk-12-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a></span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="co"># without the intercept</span></span>
<span id="cb23-3"><a href="#cb23-3"></a>SLDA &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>sparse_lda_loadings[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb23-4"><a href="#cb23-4"></a></span>
<span id="cb23-5"><a href="#cb23-5"></a><span class="co"># number of non-zero loadings</span></span>
<span id="cb23-6"><a href="#cb23-6"></a>n_nonzero &lt;-<span class="st"> </span><span class="kw">sum</span>(sparse_lda_loadings <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>)</span>
<span id="cb23-7"><a href="#cb23-7"></a></span>
<span id="cb23-8"><a href="#cb23-8"></a><span class="co"># boxplots</span></span>
<span id="cb23-9"><a href="#cb23-9"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb23-10"><a href="#cb23-10"></a><span class="kw">boxplot</span>(Z1 <span class="op">~</span><span class="st"> </span>Y,</span>
<span id="cb23-11"><a href="#cb23-11"></a>  <span class="dt">col =</span> cols, <span class="dt">ylab =</span> <span class="st">&quot;LDA&quot;</span>,</span>
<span id="cb23-12"><a href="#cb23-12"></a>  <span class="dt">main =</span> <span class="st">&quot;Entire set of 2000 genes&quot;</span></span>
<span id="cb23-13"><a href="#cb23-13"></a>)</span>
<span id="cb23-14"><a href="#cb23-14"></a><span class="kw">boxplot</span>(SLDA <span class="op">~</span><span class="st"> </span>Y,</span>
<span id="cb23-15"><a href="#cb23-15"></a>  <span class="dt">col =</span> cols, <span class="dt">ylab =</span> <span class="st">&quot;SLDA&quot;</span>,</span>
<span id="cb23-16"><a href="#cb23-16"></a>  <span class="dt">main =</span> <span class="kw">sprintf</span>(<span class="st">&quot;Subset of %d genes&quot;</span>, n_nonzero)</span>
<span id="cb23-17"><a href="#cb23-17"></a>)</span></code></pre></div>
<p><img src="Lab4-Sparse-PCA-LDA_files/figure-html/unnamed-chunk-12-2.png" width="100%" style="display: block; margin: auto;" /></p>
</details>
<p>For a simple explanation of the concept and interpretation of LDA (and other statistical methods), have a look at <a href="https://www.youtube.com/watch?v=azXCzI57Yfc" class="uri">https://www.youtube.com/watch?v=azXCzI57Yfc</a></p>
</div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-alon1999broad">
<p>Alon, Uri, Naama Barkai, Daniel A Notterman, Kurt Gish, Suzanne Ybarra, Daniel Mack, and Arnold J Levine. 1999. “Broad Patterns of Gene Expression Revealed by Clustering Analysis of Tumor and Normal Colon Tissues Probed by Oligonucleotide Arrays.” <em>Proceedings of the National Academy of Sciences</em> 96 (12): 6745–50.</p>
</div>
</div>
</div>

<div id="rmd-source-code">---
title: "Analysis of High Dimensional Data - Lab 4"
subtitle: "Sparse PCA and LDA"
author: "Adapted by Milan Malfait"
date: "19 Nov 2020"
references:
- id: alon1999broad
  type: article-journal
  author:
  - family: Alon
    given: Uri
  - family: Barkai
    given: Naama
  - family: Notterman
    given: Daniel A
  - family: Gish
    given: Kurt
  - family: Ybarra
    given: Suzanne
  - family: Mack
    given: Daniel
  - family: Levine
    given: Arnold J
  issued:
  - year: 1999
  title: Broad patterns of gene expression revealed by clustering analysis of tumor
    and normal colon tissues probed by oligonucleotide arrays
  container-title: Proceedings of the National Academy of Sciences
  publisher: National Acad Sciences
  page: 6745-6750
  volume: '96'
  issue: '12'
---

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.width = 8,
  fig.asp = 0.618,
  out.width = "100%"
)
```

***

```{r libraries, warning=FALSE, message=FALSE}
## install packages with:
## install.packages(c("glmnet", "MASS"))
library(glmnet)
library(MASS)
```


# Introduction

**In this lab session we will look at the following topics**

  - Methods to set some of the loadings exactly to zero in a PCA.
  - Use `glmnet()` to add penalties on principal component loadings.
  - Use LDA to understand differences between groups in a high dimensional space.
  
## The dataset {-}

In this practical session, we use the dataset by @alon1999broad on
gene expression levels in 40 tumour and 22 normal colon tissue samples.
They checked a total of 6500 human genes using the Affymetrix oligonucleotide array.
You can read the data in as follows:

```{r load-data}
Alon1999 <- read.csv("https://github.com/statOmics/HDA2020/raw/data/Alon1999.csv")
str(Alon1999[, 1:10])
table(Alon1999$Y)
```

The dataset contains one variable named `Y` with the values `t` and `n`.
This variable indicates whether the sample came from tumourous (`t`) or
normal (`n`) tissue.

The goal of this practical is to find the best subset/combination of genes to detect tumourous tissue.
As in @alon1999broad, we use the 2000 genes with the highest minimal intensity
across the samples.

# Sparse PCA

In order to work easily with the data, first construct a scaled matrix
`X` and a vector `Y` which gives the scaled predictors and the response
variable:

```{r}
X <- scale(Alon1999[, -1])
Y <- as.factor(Alon1999[, 1])
```

Use these objects to solve the following exercises.

## Exercises {-}

#### 1. Perform a SVD on `X`, and store the scores of the PCs in a matrix `Z`. {-}

<details><summary>Solution</summary>

Using `svd`:

```{r}
svd_X <- svd(X)
Z <- svd_X$u %*% diag(svd_X$d) # Calculate the scores
V <- svd_X$v                 # Calculate the loadings
```

Using `prcomp`:

```{r}
## X is already centered and scaled so no need to do again
pca_x <- prcomp(X, center = FALSE, scale. = FALSE)
## The scores are given by `pca_x$x`, the loadings are `pca_x$rotation`
```

</details>


#### 2. Plot the singular values and confirm that the first and second PCs can approximate the data to some extent. {-}

<details><summary>Solution</summary>

```{r pca-singular_values-plot}
## Plotting parameters
par(pch = 19, mfrow = c(1, 2))

plot(svd_X$d, type = "b", ylab = "Singular values", xlab = "PCs")

## Percentage variance explained for each PC
var_explained <- svd_X$d^2 / sum(svd_X$d^2)
plot(var_explained,
  type = "b", ylab = "Percent variance explained", xlab = "PCs",
  col = 2
)
```

</details>


#### 3. Plot the first two PCs and use different colours for tumor/normal tissue. {-}

In order to plot different colors and add a legend with base `R` plotting, you can do the following:

```{r}
par(mfrow = c(1, 1))
cols <- c("n" = "red", "t" = "blue")
plot(X[, 1], X[, 2], col = cols[Y], pch = 19)
legend("topleft", c("Normal", "Tumor"),
  col = c("red", "blue"),
  pch = 19, title = "Tissue"
)
```

This plots the first two dimensions of the `X` (!) matrix with solid
points (`pch = 19`), and the color red for normal tissue and blue for
tumorous tissue. You can adapt this code to create the proper plot.

<details><summary>Solution</summary>

```{r pca-plot}
cols <- c("n" = "red", "t" = "blue")
plot(Z[, 1], Z[, 2],
  col = cols[Y],
  xlab = "PC1", ylab = "PC2", pch = 19
)
legend("topleft", c("Normal", "Tumor"),
  col = c("red", "blue"),
  pch = 19, title = "Tissue"
)
```

__Interpretation:__ using only the first 2 PCs does not seem to separate the tumour and normal cases clearly.

</details>


#### 4. Plot histograms of the loadings of the first and second PCs. Which loadings are the most important? {-}

You can use the `hist` function to plot a histogram.
Be sure to you use an appropriate value for the `breaks` argument.

<details><summary>Solution</summary>

```{r pc-loadings, fig.asp = 1.2}
par(mfrow = c(2, 1))
# First
hist(V[, 1], breaks = 50, xlab = "PC 1 loadings", main = "")
# Add vertical line at 95% quantile
abline(v = quantile(V[, 1], 0.95), col = "red", lwd = 2)

# Second
hist(V[, 2], breaks = 50, xlab = "PC 2 loadings", main = "")
abline(v = c(
  quantile(V[, 2], 0.05),
  quantile(V[, 2], 0.95)
), col = "red", lwd = 2)
```

Vertical lines were added at the 95th percentile for PC1 and the 5th and 95th percentiles for PC2 to reflect where the "highest" (in absolute value) loadings are situated (no negative loadings for PC1, so only showing the 95th percentile).

__Interpretation:__ remember that the PC loadings reflect the *contributions* of each feature (in this case: gene) to the PC.
From these histograms it should be clear that only a minor fraction of the genes are really driving these first 2 PCs, especially for PC 2 (where the bulk of genes has loadings close to 0).

</details>


#### 5. We know that the first PC $\mathbf{Z_1}$, is given by {-}

  $$
  \mathbf{Z_1}=\mathbf{X} \mathbf{V_1}
  $$

  Where $\mathbf{V_1}$ are the loadings of the first PC. If we put this in regression notation, we get

  $$
  \mathbf{Y}=\mathbf{X}\boldsymbol{\beta}
  $$ 

  where $\boldsymbol{\beta}$ now represent the $\mathbf{V_1}$ loadings, and
  $\mathbf{Y}$ is $\mathbf{Z_1}$.

  Recall that the ridge regression solution for $\boldsymbol{\beta}$ is given by

  $$
  \boldsymbol{\beta}_{\text{ridge}}
    = (\mathbf{X^TX}+\gamma\mathbf{I})^{-1}\mathbf{X}^T\mathbf Y
  $$

  __Question:__ Replace $\mathbf{Y}$ with $\mathbf{Z_1}$ and verify in 
  `R` that

  $$
  \mathbf V_1 = 
    \frac{\boldsymbol\beta_{\text{ridge}}}{\|\boldsymbol\beta_{\text{ridge}}\|_2}
  $$

  for any $\gamma > 0$ of your choice.
  Remember that
  $\|\boldsymbol\beta_{\text{ridge}}\|_2 = \sqrt{\sum_{j=1}^p \beta_j^2}$

<details><summary>Solution</summary>

```{r, cache=TRUE}
p <- dim(X)[2]

# Let's take a ridiculously large gamma: 200
tXX_gamma_I <- t(X) %*% X + 200 * diag(p)

## This might take a while to calculate
beta_ridge <- solve(tXX_gamma_I) %*% t(X) %*% Z[, 1]

#||beta_ridge||_2
mag_beta_ridge <- sqrt(sum(beta_ridge^2))
```

For comparison, let's plot
$\boldsymbol\beta_{\text{ridge}} / \|\boldsymbol\beta_{\text{ridge}}\|_2$
against the PC1 loadings $\mathbf V_1$.

```{r beta_ridge-vs-V1-plot}
par(mfrow = c(1, 1))

# Plot against the loadings
plot(svd_X$v[, 1], beta_ridge / mag_beta_ridge,
  xlab = expression("V"[1]),
  ylab = expression(beta["ridge"] / paste("||", beta, "||")[2]),
  pch = 19
)
# Or just simply take the difference between them
max(abs(svd_X$v[, 1] - beta_ridge / mag_beta_ridge))
```

</details>

  Then you've proven that the loadings of the PCs can be computed from the
  ridge regression coefficients.
  
  We can now move on to sparse PCA, where we use penalised regression to set some of the loadings ($\boldsymbol{\beta}$s) to zero.

#### 6. We have seen elastic net type penalties. If we call the loadings of the first PC as $\boldsymbol{\beta}$ and denote PC1 as $\mathbf{Y}$, we saw that $\boldsymbol{\beta}$ can be derived by minimising the SSE: {-}

  $$
  \text{SSE}=\|\mathbf Y-\mathbf{X}\boldsymbol \beta\|^2_2+\gamma\|\boldsymbol \beta\|^2_2 \text{ for any } \gamma>0).
  $$

  Note that this equality holds for any positive $\gamma$. So we can't penalise the $\boldsymbol\beta$s not being zero by choosing a different $\gamma$.
  Remember that for ridge regression, the $\beta$'s only become 0 for $\gamma = \infty$.
  Fortunately we have other tools. 

  In addition to the $L_2$ penalization, we can use the $L_1$ penalization of Lasso. This allows us to force some of the $\boldsymbol\beta$s to become zero. The new SSE will be of the form:

  $$
  \text{SSE}=\|\mathbf Y-\mathbf{X}\boldsymbol \beta\|^2_2+\gamma\|\boldsymbol \beta\|^2_2 +\gamma_1\|\boldsymbol \beta\|_1.
  $$

  This is exactly the elastic net SSE, and $\gamma_1$ is the Lasso type penalty that sets loadings to zero. 

  Now use the `glmnet` and `cv.glmnet` functions to select an appropriate number of non-zero loadings for the first and second PCs.
  Use `alpha = 0.5` in your elastic net models and use `Z1` and `Z2` as the response variables (you should fit 2 separate models).

<details><summary>Solution</summary>

```{r PC-cv_glmnet}
par(mfrow = c(1, 2))
# For PC1
set.seed(45)
fit_loadings1 <- cv.glmnet(X, Z[, 1],
  alpha = 0.5, nfolds = 5
)
plot(fit_loadings1, main = "PC1")

# For PC2
set.seed(45)
fit_loadings2 <- cv.glmnet(X, Z[, 2], alpha = 0.5, nfolds = 5)
plot(fit_loadings2, main = "PC2")
```

To see how many features are important for each fit, we can make coefficient profile plots.
Note that the actual `glmnet` fit objects are included in the `cv.glmnet` objects under `$glmnet.fit`.

I added vertical dashed lines at `lambda.min` and `lambda.1se`.

```{r PC-glmnet-coefficient-plots, fig.asp = 1.2}
par(mfrow = c(2, 1))
plot(fit_loadings1$glmnet.fit, main = "PC1", xvar = "lambda")
abline(v = log(fit_loadings1$lambda.min), lty = 3)
abline(v = log(fit_loadings1$lambda.1se), lty = 3)
plot(fit_loadings2$glmnet.fit, main = "PC2", xvar = "lambda")
abline(v = log(fit_loadings2$lambda.min), lty = 3)
abline(v = log(fit_loadings2$lambda.1se), lty = 3)
```

To get the exact number of non-zero coefficients for `lambda.min` and `lambda.1se`, just print the `cv.glmnet` objects.
```{r}
fit_loadings1
fit_loadings2
```

__Interpretation:__ for PC1, we see that around 90 to 100 genes are most important, based on the range of $\gamma$ (`lambda`) values between `lambda.min` and `lambda.1se`.
Similarly, for PC2 we get around 65 - 80 genes.
With this information, we can now choose one of the `lambda` values and construct PCs that will have non-zero loadings for only a few genes.

</details>


#### 7. Plot your newly derived first and second PCs and use different colors for the tumor and normal tissues. How well do these new PCs separate the response classes? Compare this to the plot in exercise 3. Formulate a conclusion based on the two graphs. {-}

Use `lambda.1se` as your choice for $\gamma$.
You can extract the coefficients ($\beta$'s) from the `cv.glmnet` objects using the `coef` function, set the `s` argument to the chosen $\gamma$.
This will return a *sparse matrix* by default, so you might want to use `as.vector` to convert to a more friendly format.

<details><summary>Solution</summary>

```{r sparse-PCA-plots, fig.width = 9}
sparse_loadings1 <- as.vector(coef(fit_loadings1, s = fit_loadings1$lambda.1se))
sparse_loadings2 <- as.vector(coef(fit_loadings2, s = fit_loadings2$lambda.1se))

## How many non-zero loadings do we have (excluding the intercept)?
(non_zero1 <- sum(abs(sparse_loadings1[-1]) > 0))
(non_zero2 <- sum(abs(sparse_loadings2[-1]) > 0))

SPC1 <- X %*% sparse_loadings1[-1] # without the intercept
SPC2 <- X %*% sparse_loadings2[-1] # without the intercept

par(mfrow = c(1, 2))
plot(Z[, 1], Z[, 2],
  col = cols[Y], xlab = "PC1", ylab = "PC2", pch = 16,
  main = "All 2000 genes \nfor PC1 and PC2"
)
legend(-45, -25,
  legend = c("Normal tissue", "Tumor tissue"), bty = "n",
  col = c("red", "blue"), pch = c(16, 16), cex = 1
)
plot(SPC1, SPC2,
  col = cols[Y], xlab = "SPC1", ylab = "SPC2", pch = 16,
  main = paste(non_zero1, "genes for SPC1 \n and", non_zero2, "genes for SPC2")
)
legend(-45, -25,
  legend = c("Normal tissue", "Tumor tissue"), bty = "n",
  col = c("red", "blue"), pch = c(16, 16), cex = 1
)
```

__Conclusion:__ Only about 
`r sprintf("%.2f", 100 * non_zero1 / length(sparse_loadings1))`% (`r non_zero1`) of the genes are useful for PC1 and only about
`r sprintf("%.2f", 100 * non_zero2 / length(sparse_loadings2))`% (`r non_zero2`) of the genes are useful for PC2 .
Sparse PCA has succeeded in setting the uninformative genes/loadings to zero.
In seperating normal and tumour tissues, SPCA performs vitually the same as PCA.
The key point here is that SPCA uses only a minor proportion of the original features to achieve the same results, suggesting that the largest variability of the data is only driven by a minority of features. 

</details>


# LDA

In this section, we will perform LDA on the gene data to get a clear understanding on the genes responsible for separating the tumor and normal tissue groups.

Remember that the LDA problem can be stated as

$$
\mathbf{v}
  = \text{ArgMax}_a \frac{\mathbf{a^T B a}}{\mathbf{a^T W a}}
    \text{ subject to }
    \mathbf{a^T W a} = 1
$$

Which is equivalent to the eigenvalue/eigenvector problem 

$$
\mathbf W^{-1} \mathbf B \mathbf a=\lambda \mathbf a
$$

In our case, where we only have two groups, only one solution exists.
This is the eigenvector $\mathbf v$ and its eigenvalue.
We can then write the PC-scores as

$$
\mathbf Z=\mathbf X \mathbf v
$$


## Exercises {-}

#### 1. The function `lda()` in the `MASS` package performs LDA. Similar to the `glmnet()` function, you will need to supply an `x` argument. The argument `grouping` is the vector with the response, and this has to be a factor variable. You have that stored as `Y`. Fit an LDA on `X` with grouping `Y`. {-}

<details><summary>Solution</summary>

```{r}
## Perform LDA
alon_lda <- lda(x = X, grouping = Y)
```

Note the warning regarding collinearity.

</details>

#### 2. $\mathbf v$ can be extracted from the object as the element `scaling`. Extract this and call it `V1`. {-}

<details><summary>Solution</summary>

```{r}
V1 <- alon_lda$scaling
```

</details>

#### 3. Compute $\mathbf Z$ and call it `Z1`. {-}

<details><summary>Solution</summary>

```{r}
Z1 <- X %*% V1
```

</details>

#### 4. Now check to see how well your single LDA/`Z1` separates the tumour and normal tissues groups. Compare it to the plot in (3) of the previous exercise, and observe whether LDA performs better in separating the two groups. {-}

You could use a boxplot for visualization, but feel free to be creative!

<details><summary>Solution</summary>

```{r}
par(mfrow = c(1, 1))
boxplot(Z1 ~ Y, col = cols, ylab = expression("Z"[1]), 
        main = "Separation of normal and tumour samples by LDA")
```

</details>

#### 5. As was the case with the first and second PC, `Z1` is a linear combination determined by the loadings $\mathbf v$. These are non-zero for all genes. To get a few interesting genes, you can use a sparse LDA. Note that you can use the package `sparseLDA` with the function `sda()` to perform this analysis, but let's do this as we did for sparse PCA. {-}

a. Use the `cv.glmnet` function with `x=X`, `y=Z1` and `alpha=0.5` to select an appropriate number of non-zero genes for the LDA.

<details><summary>Solution</summary>

```{r}
set.seed(45)
lda_loadings <- cv.glmnet(X, Z1, alpha = 0.5, nfolds = 5)
plot(lda_loadings)
```

</details>

b. Check to see how well this subset of genes does in separating the tumour and normal tissue groups. Are they as effective as the entire set of genes?

<details><summary>Solution</summary>

```{r}
sparse_lda_loadings <- as.vector(
  coef(lda_loadings, s = lda_loadings$lambda.1se)
)

# See the genes involved
plot(sparse_lda_loadings[sparse_lda_loadings != 0],
  pch = 16, type = "n", xlim = c(0, 20)
)
text(
  sparse_lda_loadings[sparse_lda_loadings != 0],
  colnames(X)[sparse_lda_loadings != 0]
)
abline(h = 0, lwd = 3)

# without the intercept
SLDA <- X %*% sparse_lda_loadings[-1]

# number of non-zero loadings
n_nonzero <- sum(sparse_lda_loadings != 0)

# boxplots
par(mfrow = c(1, 2))
boxplot(Z1 ~ Y,
  col = cols, ylab = "LDA",
  main = "Entire set of 2000 genes"
)
boxplot(SLDA ~ Y,
  col = cols, ylab = "SLDA",
  main = sprintf("Subset of %d genes", n_nonzero)
)
```

</details>


For a simple explanation of the concept and interpretation of LDA (and other statistical methods), have a look at <https://www.youtube.com/watch?v=azXCzI57Yfc>



# References {-}
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("Lab4-Sparse-PCA-LDA.Rmd");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
